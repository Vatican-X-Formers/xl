# Base
enwik8: &enwik8
  dataset: enwik8
  data: ../data/enwik8/

train: &train
  <<: *enwik8
  cuda: true
  n_layer: 0
  d_model: 512
  n_head: 8
  d_head: 64
  d_inner: 2048
  dropout: 0.15
  dropatt: 0.15
  optim: adam
  lr: 0.00041
  eta_min: 0.0
  warmup_step: 4000
  max_step: 200000
  tgt_len: 2049
  mem_len: 0
  eval_tgt_len: 2049
  batch_size: 8
  multi_gpu: ddp
  log_interval: 100
  eval_interval: 5000
  vocab: word
  adaptive: false
  funnel_config: "[2, (8, 3), 2]"
  funnel_resample: naive
  pre_lnorm: true
  roll: true

eval: &eval
  <<: *enwik8
  cuda: true
  tgt_len: 80
  mem_len: 2100
  clamp_len: 820
  same_length: true
  split: test

default:
  train:
    <<: *train
  eval:
    <<: *eval

dgx1_4gpu_fp32: &dgx1_4gpu_fp32
  train:
    <<: *train
    batch_chunk: 1
  eval:
    <<: *eval
