# Base
text8: &text8
   dataset: text8
   data: ../data/text8/

train: &train
   <<: *text8
   cuda: true
   n_layer: 0
   d_model: 512
   n_head: 8
   d_head: 64
   d_inner: 2048
   dropout: 0.1
   dropatt: 0.0
   optim: adam
   lr: 0.00025
   warmup_step: 4000
   max_step: 400000
   tgt_len: 2049
   mem_len: 0
   eval_tgt_len: 2049
   batch_size: 1
   multi_gpu: ddp
   log_interval: 100
   eval_interval: 5000
   batch_chunk: 1
   pre_lnorm: true
   funnel_config: "[8, (0, 1), 0]"
   funnel_resample: naive

default:
   train:
      <<: *train